---
layout:     post
title:      "支持向量机学习随笔"
subtitle:   "svm学习中的心得和笔记"
date:       2017-04-17 12:00:00
author:     "zfl"
header-img: "img/post-sklearn-svm.jpg"
header-mask: 0.6
catalog:    true
tags:
    - 机器学习
    - svm
    - 感知机
---

# 支持向量机随笔
## 前言  
一直想写一篇关于支持向量机的文章，因为它是我的机器学习生涯中第一个遇到的大难题，前后花了很长时间去研究，现在还在不断的深入学习之中，对于不求甚解的同学也可以直接下载LIBSVM或者sklearn.svm等类库使用，but，个人觉得这个算法真的特别强大、也特别有意思，思路之精妙、逻辑之严谨让我叹为观止，也向该算法的发明者以及后来的研究者致以崇高的敬意。  
本文只是本人闲暇之余做的学习笔记，难免有疏漏、不妥之处，不吝赐教。
## 一 svm简介
支持向量机（Support Vector Machine，常用简称：svm）是一种**二类分类模型**，**非线性的分类器**，算法的学习策略是**间隔最大化**，进而可以转化为求解**凸二次规划的最优化算法**。  
svm包含由简至繁的模型：**线性可分支持向量机**、**线性支持向量机**、**非线性支持向量机**，其中简单的是复杂的基础，也是复杂模型的特殊情况。
我们来找一个通俗的例子来描述这三种模型，在桌子上假如有一堆红豆和一堆黄豆：
- 1 线性可分支持向量机，如下图：
![image](http://upload-images.jianshu.io/upload_images/730879-8ac6ee89c5c75a00.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)   

可以看出，通过画一条线，我们就可以很容易的把他们区分开，如果我们只是随意的、普普通通的画一条直线把二者区分开，这就是**感知机**。  
现在我们在画直线的时候使这条直线跟这些红豆、黄豆的间隔最大，那么首先最大的限制使得显然这条直线只有唯一的一条，通过**硬间隔最大化**可以得到这样一条唯一的直线。我们给这条直线加的限制就是svm区别于感知机的地方所在。  

- 2 线性支持向量机：

![svm-2.png](http://upload-images.jianshu.io/upload_images/730879-c494c19cad80522f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

如图：加入有一些黄豆、红豆中的坏分子跑到了对方的大本营，使得不存在一条直线能完全正确的区分二者，但是整体又是可以区分的，这时候就要使用**软间隔最大化**来找到这一条直线。
- 3 非线性支持向量机  

![svm-3.png](http://upload-images.jianshu.io/upload_images/730879-c87aab4e598e6ec3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  

如图：红豆、黄豆就这样被人搓麻将一样搅和在了一起，再也没有可能去找一条直线将其划分开，这时，我们奋力垂直的抬起桌子，让这些豆豆都收到一个垂直向上的推力，加入我们选择的黄豆都是颗粒饱满、红豆都是干瘪的，黄豆的单个质量比较大，红豆的都偏小，黄豆的重力也就偏大，这就导致了受到同样的力黄豆上升的距离比较短，可能某一时刻，会出现下图的这种分布：
![svm-4.png](http://upload-images.jianshu.io/upload_images/730879-259697e14db6401f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  

是不是很神奇，这样就可以找一个平面把黄豆红豆划分开，上面就是把本来存在在二维里的黄豆红豆拓展到了三维空间，这种维数扩展的方法就叫**核函数**。  
总结：以上就是关于svm的关键字的直观通俗的解释，接下来就是详细的介绍，其中涉及到了很多数学公式和数学原理哦。
## 二 svm详解
### 1 感知机
感知机（perceptron）1957年由Rosenblatt提出，是**神经网络**与**支持向量机**的**基础**，在神经网络中可以看作是一个单位神经元。感知机是二类分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别，取+1和-1二值。对于线性可分的数据找到一个线性划分的超平面，相当于上面豆子例子中的找到一条线将红豆和黄豆分开，只要能分开就行，没有其他的限制。
为了得到这个超平面，使用基于误分类的损失函数，利用**梯度下降法**对损失函数进行极小化，感知机的学习算法非常简单，有**原始形式** 和 ** 对偶形式 **。

# <未完待续>